---
title: "Data Analysis"
author: "Tim Abramov"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readxl)
library(dplyr) ##for different filter()
##library(e1071) ##needed for normality graphs
library(mosaic)##favstats

games_features <- read_xlsx("games_features.xlsx")
##we need only games:
games <- filter(games_features, GenreIsNonGame == FALSE)
```

## Question 1
__"Are there any associations that can be observed between games that received a Metacritic score and those that didn't?"__
```{r echo = FALSE}
##then group by if metacritic != 0 (one group of games that received the score, and one that didn't)

```


## Question 2
__"Is there an association between number of screenshots in game description and the sales of the game?"__

To visualize the relationship, let's graph a scatterplot first:
```{r echo = FALSE}
##ScreenshotCount vs. SteamSpyOwners
##1. Scatterplot, to visualize the relationship
scatter.smooth(x=games$ScreenshotCount, y=games$SteamSpyOwners, main="ScreenshotCount ~ SteamSpyOwners")
##gf_point(SteamSpyOwners ~ ScreenshotCount, data = games)
```

Not much can be seen at that scale, too many outliers. 

Speaking of which, to see if we have any outliers (and how many), let's graph boxplots for both the "ScreenshotCount" and "SteamSpyOwners":
```{r echo = FALSE}
##2. BoxPlots
par(mfrow=c(1, 2))  # divide graph area in 2 columns
boxplot(games$ScreenshotCount, main="ScreenshotCount",
sub=paste("Outliers: ", length(boxplot.stats(games$ScreenshotCount)$out)))  # box plot for ScreenshotCount
boxplot(games$SteamSpyOwners, main="SteamSpyOwners",
sub=paste("Outliers: ", length(boxplot.stats(games$SteamSpyOwners)$out)))  # box plot for SteamSpyOwners
```

As you can see, we have quite a few outliers. 530(around 4% of the dataset) for number of screenshots for a game, and 1981 (around 15% of the dataset) for number of owners for a game! To proceed with linear regression, we will need to deal with those outliers.

I won't be getting rid of outliers, since they were collected the same way all the other data was collected (they're not a mistake) and are significant for the question(s) I want to answer. To help linearize the relationships between the variables, I will transform the data needed into either log or square root of it. Let's see which will work the best.

```{r echo=FALSE}
##creating logs
games$screen_log <- log(games$ScreenshotCount)
games$owners_log <- log(games$SteamSpyOwners)
##creating sqrt
games$screen_sqrt <- sqrt(games$ScreenshotCount)
games$owners_sqrt <- sqrt(games$SteamSpyOwners)
##scatter.smooth(x=games$screen_log, y=games$owners_log, main="ScreenshotCount ~ SteamSpyOwners(logs)")
gf_point(owners_log ~ screen_log, data = games) %>% gf_lm()
gf_point(owners_sqrt ~ screen_sqrt, data = games) %>% gf_lm() 
```

While it's still not easy to see, but there appears to be linear relationship between our variables. Due to the nature of how log works, when I "logged" my variables, records with zeroes in them were removed. Since zero values do matter to us (free games or games without screenshots), I decided to proceed with using square roots of our variables.

To use linear regression on our variables, there are a 4 main assumptions we need to verify:
1.Is it indeed a linear relationship between the variables?
2.Are the residuals normally distributed?
3.Is there constant variance around the regression line at each x-location?
4.Is the data independent (random)?

```{r echo = FALSE}
screen_fit_sqrt <- lm(owners_sqrt ~ screen_sqrt, data = games)
##screen_fit_log <- lm(owners_log ~ screen_log, data = games)
mplot(screen_fit_sqrt, which = 1)
mplot(screen_fit_sqrt, which = 2)
mplot(screen_fit_sqrt, which = 3)
```

From the "Residuals vs Fitted" plot we can see that it's indeed a linear relationship, since the red line is mostly horizontal. In terms of normality of residual distribution, from "Normal Q-Q" plot we can see that it's not the case. Also, from "Scale-Location" plot we can observe that there doesn't exist a constant variance around the regression line at each x-location. Since each and every game is a unique thing and and parameters of one game usually doesn't depend on parameters from the other game, I will assume that our data is independent.
As we can see, our data fails 2 out of 4 assumptions: normality of residual distribution and a constant variance around the regression line. Because of that regression analysis is not the ideal tool to assess the assosiation between those variables. But since it's the best way to do it that I know, I will procede with it, just need to keep in mind those failed assumptions:


```{r}
cor(owners_sqrt ~ screen_sqrt, data = games)
summary(screen_fit_sqrt)
```

Firstly, checking correlation between variables - it's pretty low. By running a summary analysis of our regression line we can derive our linear regression formula:
y = 15.239 + 67.715 * x
owners = 15.239 + 67.715 * screenshots

Using a linear regression model for this data have proven to be not the best approach: it failed 2 out 4 assumptions to use linear model and does have really weak corellation using this model.


## Question 3
__"Is there an association between how many copies of the game were sold and the price of the game?"__

To visualize the relationship, let's graph a scatterplot first:

```{r echo = FALSE}
##ScreenshotCount vs. SteamSpyOwners
##1. Scatterplot, to visualize the relationship
scatter.smooth(x=games$PriceFinal, y=games$SteamSpyOwners, main="PriceFinal ~ SteamSpyOwners")
```

As with previous question, can't really say much at this stage. Again, problems with outliers

Let's graph boxplots for both the "PriceFinal" and "SteamSpyOwners":
```{r echo = FALSE}
##2. BoxPlots
par(mfrow=c(1, 2))  # divide graph area in 2 columns
boxplot(games$PriceFinal, main="PriceFinal",
sub=paste("Outliers: ", length(boxplot.stats(games$PriceFinal)$out)))  # box plot for ScreenshotCount
boxplot(games$SteamSpyOwners, main="SteamSpyOwners",
sub=paste("Outliers: ", length(boxplot.stats(games$SteamSpyOwners)$out)))  # box plot for SteamSpyOwners
```

Number of outlier is similar to previous question. 660(around 5% of the dataset) for final price for a game, and 1981 (around 15% of the dataset) for number of owners! What is pretty interesting, is that most games are bellow $25 mark, which makes sense, just never thought of it before. Before we move on to the next stage, something needs to be done about those outliers.


Since in question (2) we determined that values of 0 do matter to us, we will try to square root our data to help linearize the relationship between final price of the game and it's owner count:

```{r}
##creating sqrt
games$priceFinal_sqrt <- sqrt(games$PriceFinal)
##scatter plot
gf_point(owners_sqrt ~ priceFinal_sqrt, data = games) %>% gf_lm() 
```

Linear relationship is basically impossible to spot at this point.

Let's check our assumptions for using a linear model:
1.Is it indeed a linear relationship between the variables?
2.Are the residuals normally distributed?
3.Is there constant variance around the regression line at each x-location?
4.Is the data independent (random)?

```{r echo = FALSE}
priceFinal_fit_sqrt <- lm(owners_sqrt ~ priceFinal_sqrt, data = games)
##screen_fit_log <- lm(owners_log ~ screen_log, data = games)
mplot(screen_fit_sqrt, which = 1)
mplot(screen_fit_sqrt, which = 2)
mplot(screen_fit_sqrt, which = 3)
```

The same situation this time: data is independent and it's a linear relationship ("Residuals vs Fitted" plot), but residuals are not normally distributed (Normall Q-Q) and there is no constant variance around the regression line at each x-location. Thus, this time around, linear regression model is also not the best fit for these variables. Ohh well, let's see what kind of correlation we will get and what is the equation for linear regression:


```{r}
cor(games$SteamSpyOwners, games$PriceFinal)
summary(priceFinal_fit_sqrt)
```

For this question, using linear regression model, correlation is basically non-existent at 0.05 and our equation is:
y = 140.3 + 30.5 * x
owners = 140.3 + 30.5 * priceFinal

Similar to question (2) using linear regression for this data is a bad fit, especially this time - correlation is basically non-existent. Unfortunately this is the best model for the situation I know at the moment, most likely there are better ways to assess this question. 





